\chapter{Einleitung}
\label{ch:einleitung}
Obwohl die Idee für eine Maschine, die anhand eingegebener Daten selbständig Entscheidungen treffen kann und die ersten praktischen Ansätze für künstliche neuronale Netze schon einige Jahrzehnte alt sind, findet der Einsatz derartiger Algorithmen erst seit einigen Jahren statt. Viele Erfindungen, die vor 30 bis 50 Jahren in Filmen und Serien Science Fiction darstellten, sind inzwischen nicht nur Realität, sondern auch alltagstauglich. Zu den wichtigsten Beispielen zählen verbale Schnittstellen an Computersystemen und in Armbanduhren, autonome Fahrzeuge etwa in Gestalt von Parkassistenten und verschiedene Verfahren zur biometrischen Identitätsprüfung.

Andere rasche technologische Fortschritte aus der Vergangenheit haben nicht immer nur die Lebensqualität der beteiligten Personen erhöht, sondern stellten durch Missbrauch gelegentlich sogar Gefahren dar. So wie das Internet auch zur Verbreitung von Falschinformationen und die sichere Verschlüsselung von gespeicherten Daten auch zur Verschleierung von Straftaten genutzt werden kann, ist die Generierung von täuschend echten Bildern unter Umständen geeignet, persönlichen, finanziellen oder anders gearteten Schaden zu verursachen.

Weiterhin existieren bei der Auswahl der Trainingsdaten für künstliche neuronale Netze rechtliche Grenzen. Bilddaten sind in mehr als ausreichenden Mengen vorhanden, berücksichtigen aber zum Beispiel nicht immer das Recht am eigenen Bild. Für diese Bachelorarbeit sind die Anforderungen an die Bildqualität außerdem sehr hoch, da möglichst auch Texturen und Lichtreflexionen erlernt werden sollen. Modellgrafiken mit geeigneten Material- und Beleuchtungseigenschaften gibt es zwar auch, aber nur in weitaus geringeren Mengen. Für solche Fremdarbeiten, die sehr arbeitsaufwendig sind, wäre auch die Klärung der Nutzungsrechte erforderlich geworden. Für Trainingsergebnisse, die das mentale Modell einer breiten Nutzergemeinschaft reflektieren, sind grundsätzlich auch Daten aus möglichst vielen verschiedenen Quellen erforderlich.

Es ist deshalb eine Brücke geschlagen worden zwischen Trainingsdaten, die zum einen aus zufällig ausgewählte Benutzereingaben bestehen, und solchen, die bestimmte Qualitätseigenschaften erfüllen und in beliebiger Menge erstellt werden können. Ein künstliches neuronales Netz soll aus Skizzen des ``Quick, Draw!''-Datasets von Google hochwertig gestaltete Figuren generieren.

\section{Ziel der Arbeit}
\label{sec:ziel}
Für diese Arbeit habe ich mir zum Ziel gesetzt, anhand wissenschaftlicher Literatur die Grundlagen und Methoden des maschinellen Lernens zu erarbeiten. Im Rahmen des Themas dieser Abschlussarbeit habe ich mit verschiedenen künstlichen neuronalen Netzen experimentiert, um Bilder zu generieren.

Im Zuge der Ausarbeitung des Konzeptes waren zunächst verschiedene Rahmenbedingungen zu bewerten. Trainingsdaten müssen in großen Mengen verfügbar sein. Urheberrechtliche oder gar Lizenzfragen sollten möglichst nicht auftreten. Weiterhin sollten die Eingabebilder eine gewisse Homogenität aufweisen, um ein Modell auf die Aspekte Textur und Shading trainieren zu können. Meine Recherche verschiedener Methoden zur Generierung von Bildern mittels künstlichen neuronalen Netzen ist im \hyperref[sec:related]{nächsten Abschnitt zu den bisherigen Arbeiten} näher beschrieben.

Die Entscheidung fiel schließlich auf ein Machine-Learning-Modell, das unter anderem die Ergebnisse der Canny-Edge-Detection \cite{canny1986edge} eines Bildes, also nur die Umrisse des abgebildeten Objekts, in das Originalbild zurückübersetzen kann. Das Modell heißt Image-To-Image-Translation \cite{isola2018imagetoimage} oder kurz Pix2Pix. In meinen Experimenten habe ich das Modell erfolgreich darauf trainiert, handgezeichnete Skizzen in fotorealistische Abbildungen von Alltagsgegenständen zu übersetzen. Die Grundlagen und Bausteine des Algorithmus sind \hyperref[sec:model]{Kapitel 2} und der Algorithums selbst und seine Implementierung in Python im Abschnitt zu \hyperref[sec:pix2pix]{Image-To-Image-Translation} in \hyperref[ch:impl]{Kapitel 3} beschrieben.

Eine umfangreiche Sammlung an handgezeichneten Eingabebildern ist im Dataset des ``Quick, Draw!''-Minigames von Google zu finden. Ziel des kostenlosen Browser-Spiels ist es, ein vorgebenes Motiv innerhalb 20 Sekunden mittels Maus, Touchpad oder einem vergleichbaren Eingabegerät so zu zeichnen, dass ein zeitgleich aktiver Algorithmus die Zeichnung klassifizieren kann. Das Dataset besteht aus den erstellten Zeichnungen, ist nach Motiven sortiert und ebenfalls kostenlos verfügbar. Somit ist es für meine Experimente bestmöglich geeignet. Das Minigame ist auf \href{https://quickdraw.withgoogle.com/}{https://quickdraw.withgoogle.com/} zu finden. Die Verwendung des ``Quick, Draw!''-Datasets ist in \hyperref[ch:conduct]{Kapitel 4} beschrieben.

Es gibt verschiedene denkbare praktische Anwendungsfälle für diese automatische Übersetzung. Vergleichbar mit Handschrifterkennung oder der Erkennung primitiver geometrischer Formen durch Geräte mit Stift- oder Fingereingabe kann die Erkennung von handgezeichneten Alltagsgegenständen etwa durch Smartboards die Illustration von Alltagssituationen erleichtern. In meinen Experimenten habe ich Skizzen von Autos in fotorealistische Abbildungen übersetzt. Damit ist die Darstellung einer Situation im Straßenverkehr vorstellbar, wie sie in einer Fahrschule vorteilhaft sein könnte. Ein weiterer konkreter Anwendungsfall ist der elektronisch gestützte Entwurf einer Inneneinrichtung mit verschiedenen Möbelstücken.

Es ist in begrenztem Maße möglich, die Zahl der vorhandenen Eingabebilder durch Data Augmentation zu erhöhen \cite{chollet2021deep}. Dabei werden die Bilder gespiegelt, gedreht, skaliert oder auf andere Weise verändert oder verfälscht. Es ist außerdem denkbar, die Eingabedaten selbst zu erstellen. Weil der Zusammenhang mit prozeduralen Shadern durch die Aufgabenstellung gegeben ist, habe ich mich dazu entschieden einen wesentlichen Teil der Eingabebilder zu entwerfen und automatisiert zu erstellen. Es sind Bilder verschiedener Alltagsgegegenstände entstanden, die sich in der Form unterscheiden, deren Texturen und Lichtverhältnisse sich aber gleichen. Dadurch war es mir möglich das Modell auf die Übersetzung der handgezeichneten Skizzen in passende, fotorealistische Bilder zu trainieren. Das Erstellen der 3D-Modelle sowie die Automatisierung ist ebenfalls in \hyperref[ch:conduct]{Kapitel 4} beschrieben.

Eingabedaten für das Training der Image-To-Image-Translation sind also zum einen handgezeichnete Skizzen und zum anderen fotorealistische Abbildungen alltäglicher Gegenstände. In der Literatur wird häufig das Bild, das übersetzt werden soll, als Input bezeichnet. Das Bild, in das übersetzt werden soll, wird Ground Truth oder Target genannt \cite{chollet2021deep}. Ich verwende in diesem Dokument dieselben Bezeichnungen oder die deutschen Übersetzungen Eingabebild für Input und Zielbild für Target.

Im Verlauf der Experimente habe ich den Trainingsfortschritt und -erfolg verschiedener Eingabebilder und Algorithmen betrachtet. Die interessantesten Größen beim maschinellen Lernen sind die Menge der Eingabedaten, die Anzahl der Trainingsdurchläufe und im Zusammenhang damit die Dauer des Trainings. Das tatsächliche Trainingsergebnis habe ich in Augenschein genommen und subjektiv für zufriedenstellend oder nicht zufriedenstellend befunden.

\begin{figure}[h]
	\centering
	\includegraphics[width=0.3\textwidth]{bilder/0.jpg}
	\includegraphics[width=0.3\textwidth]{bilder/1.jpg}
	\includegraphics[width=0.3\textwidth]{bilder/15.jpg}
	\caption[Verschiedene Trainingsschritte]{Das Modell generiert das Ergebnis in mehreren Tausend Schritten aus zufälligem Rauschen.}
	\label{fig:trainingsteps}
\end{figure}

% Die Arbeit verfolgt das Ziel, verschiedene bewährte Architekturen künstlicher
% neuronaler Netze zur Generierung von Bildern zu untersuchen und in einem
% praxisorientierten Zusammenhang zu testen. Ich zeige mehrere Möglichkeiten,
% wirklichkeitsnahe Bilder von Alltagsgegenständen aus Skizzen, die durch Benutzer
% erstellt wurden, mittels eines künstlichen neuronalen Netzes zu generieren. Die
% Bilddateien der Skizzen sowie die generierten Bilddateien können dabei aus
% RBG-Pixelinformationen bestehen oder die Grafik mittels Bildkoordinaten beschreiben,
% wie es bei Vektorgrafiken und 3D-Modellen der Fall ist. Eine Anwendung der
% Ergebnisse ist beispielsweise als Feature eines Grafiktablets oder eines
% Smartboards denkbar.

\section{Bisherige Arbeiten}
\label{sec:related}
Künstliche neuronale Netze finden erst seit wenigen Jahren breite Aufmerksamkeit, seit auch Heimcomputer in der Lage sind die hohe Anzahl der erforderlichen Rechenoperationen in annehmbarer Zeit auszuführen. Seitdem sind wenige, englischsprachige Einführungen in die Thematik entstanden. Ein häufig genanntes Buch ist ``Deep Learning'', das online kostenfrei zugänglich ist \cite{goodfellow2016deeplearning}. Ebenfalls online und kostenfrei ist das Buch ``Dive into Deep Learning'' \cite{zhang2020dive}. Ein weiteres, praxisorientierteres Buch ist ``Deep Learning with Python'' \cite{chollet2021deep}, das inzwischen in der zweiten Auflage erschienen ist.

Erste Recherchen haben verschiedene Arten und Implementierungen Bilder generierender künstlicher neuronaler Netze herausgestellt. Das Model aus ``DRAW: A Recurrent Neural Network For Image Generation'' \cite{gregor2015draw} kann darauf trainiert werden, handschriftliche Ziffern wie die des MNIST-Datasets \cite{deng2012mnist} zu generieren.

Die Schlüsselerkenntnis in ``A Neural Algorithm of Artistic Style'' \cite{gatys2015nst} ist, dass Inhalt und Stil eines Bildes voneinander getrennt werden können. Das Model kann zum Beispiel den Stil eines Künstlers auf das Bild eines anderen übertragen.

In anderen Ansätzen mit rekurrenten neuronalen Netzen wird jedes Eingabebild in eine Sequenz von Pixeln umgeformt. Anschließend wird das künstliche neuronale Netz darauf trainiert, teilweise geschwärzte Bilder wieder zu vervollständigen \cite{chen2020generative}, \cite{oord2016pixel}. Es werden auch Bilder generiert und die Fähigkeit des jeweiligen Modells, die Darstellung von Bildern zu lernen, untersucht und mit der anderer Modelle verglichen. Ein weiterer, ebenfalls rekurrenter Algorithmus generiert Bilder aus textuellen Beschreibungen \cite{ramesh2021zeroshot}.

Besondere Aufmerksamkeit habe ich den Generative Adversarial Networks \cite{goodfellow2014generative} gegeben. Die Ergebnisse dieser Familie von künstlichen neuronalen Netzen sind teilweise erstaunlich gut, und es gibt bereits einige Beispielanwendungen und frei verfügbaren Quelltext. Je nach Anwendung des Models variiert die Qualität der Resultate.

In ``Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks'' \cite{radford2016unsupervised} werden ebenfalls
realitätsnahe Ergebnisse erzielt. Anders als bei den bisher erwähnten Arbeiten
wird Unsupervised Learning verwendet, um das künstliche neuronale Netz zu trainieren.

Die vielseitigste Generierung von Bildern bietet Image-To-Image-Translation with Conditional Adversarial Networks \cite{isola2018imagetoimage}. In der Arbeit werden Labels in Fotos zurückübersetzt, Schwarzweißbilder koloriert und weitere Anwendungsbeispiele gezeigt. Vor allem die Übersetzung ``Kanten nach Foto'' (``Edges to Photo'') ist für mein Vorhaben relevant. Das Dokument enthält dafür mehrere Beispiele. Der Algorithmus setzt auf Generative Adversarial Networks \cite{goodfellow2014generative} und Conditional Generative Adversarial Networks \cite{mirza2014conditional} auf.

\begin{figure}[h]
	\centering
	\includegraphics[width=0.6\textwidth]{bilder/table1small.png}
	\includegraphics[width=0.6\textwidth]{bilder/table2small.png}
	\includegraphics[width=0.6\textwidth]{bilder/table3small.png}

	\includegraphics[width=0.6\textwidth]{bilder/candle1small.png}
	\includegraphics[width=0.6\textwidth]{bilder/candle2small.png}
	\includegraphics[width=0.6\textwidth]{bilder/candle3small.png}
	\caption[Eigene Beispiele]{Meine Ergebnisse zeigen, dass aus einer Handzeichnung ein fotorealistisches Bild generiert werden kann. Die generierten Bilder nehmen ungefähr die Proportionen der Handzeichnungen an, erstellen realistische Darstellungen der Gegengenstände und fügen Texturen und Lichteffekte hinzu.}
	\label{fig:myexamples}
\end{figure}

Eine für die Vorbereitung meiner Experimente erforderliche Software ist Blender. Die Software ist kostenlos verfügbar und ermöglicht die Modellierung von 3D-Szenen. Objekte können aus vorgegebenen Würfeln, Zylindern und vielen weiteren Körpern und auch Flächen erstellt, skaliert und mit verschiedenen Werkzeugen verformt werden. Es stehen Lichtquellen zur Verfügung, und eine Szene kann als Bilddatei gespeichert werden. Zur Verwendung der Software gibt es eine große Auswahl an Literatur. 
